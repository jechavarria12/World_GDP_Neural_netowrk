# üåç Predicci√≥n de Categor√≠as de PIB con Redes Neuronales

üìù Autores

[*Mariana Solano Pineda*](https://www.linkedin.com/in/mariana-solano-pineda/)
Estudiante de econom√≠a y administraci√≥n de empresas Universidad de Los Andes

[*√Ångela Aparicio*](www.linkedin.com/in/aparicio-angela)
Estudiante de econom√≠a Universidad de Los Andes

[*Juan David Salda√±a Rivera*](https://www.linkedin.com/in/juan-david-salda%C3%B1a-rivera-829ab62b3/)
Estudiante de econom√≠a Universidad de Los Andes

[*Juan Jos√© Echavarr√≠a Villamizar*](www.linkedin.com/in/juan-jose-echavarria-villamizar)
Estudiante de econom√≠a Universidad de Los Andes

[*Juan Diego Barrios Esteban*](https://www.linkedin.com/in/juan-diego-barrios-esteban-6b684028b)
Estudiante de econom√≠a Universidad de Los Andes

üìö Descripci√≥n

Este proyecto utiliza redes neuronales para predecir la categor√≠a del PIB de distintos pa√≠ses, transformando un problema de regresi√≥n en clasificaci√≥n. Se entrenan y comparan distintos modelos para evaluar su desempe√±o en la predicci√≥n del PIB a partir de datos macroecon√≥micos.

üéØ Planteamiento del Problema

El objetivo es clasificar los pa√≠ses en tres categor√≠as de PIB: bajo, medio y alto, a partir de sus datos hist√≥ricos. Para ello, se emplean modelos de aprendizaje profundo con distintas arquitecturas y funciones de optimizaci√≥n.

üìÇ Contenido del Repositorio
	‚Ä¢	main.ipynb ‚Äì Cuaderno principal con la implementaci√≥n de modelos y an√°lisis de resultados.
	‚Ä¢	README.md ‚Äì Este archivo con la descripci√≥n del proyecto y la relator√≠a
	‚Ä¢	gdp_data.csv ‚Äì Datos hist√≥ricos del PIB mundial.
	‚Ä¢	country_codes.csv ‚Äì C√≥digos de pa√≠ses utilizados en el an√°lisis.

ü§ñ Modelos Implementados
	1.	Red Neuronal con Scikit-Learn ‚Äì Implementaci√≥n b√°sica con ajuste de hiperpar√°metros.
	2.	Red Neuronal Profunda con TensorFlow ‚Äì Modelo avanzado con m√∫ltiples capas ocultas.
	3.	Modelo con Mala Funci√≥n de P√©rdida ‚Äì Evaluaci√≥n del impacto de una mala configuraci√≥n y su correcci√≥n.

üìä Evaluaci√≥n de Modelos

Se analizan los modelos mediante:
	‚Ä¢	Curvas de p√©rdida y precisi√≥n
	‚Ä¢	Matriz de confusi√≥n y m√©tricas de clasificaci√≥n
	‚Ä¢	Comparaci√≥n de tasas de aprendizaje
	‚Ä¢	Curva ROC y an√°lisis de importancia de variables

üöÄ Requerimientos
	‚Ä¢	Python 3.x
	‚Ä¢	Librer√≠as: numpy, pandas, scikit-learn, tensorflow, matplotlib, seaborn, shap

üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT.

üìö Relator√≠a del equipo:

- **Mi√©rcoles 12/03/2025**

Juan Jos√© cre√≥ el repositorio de GitHub y lo comparti√≥ con el equipo a trav√©s de un grupo de WhatsApp, el cual hab√≠a sido creado previamente por Mariana para asegurar una comunicaci√≥n efectiva. En paralelo, se discuti√≥ la mejor manera de organizar la divisi√≥n del trabajo para la realizaci√≥n del parcial.

Se tom√≥ la decisi√≥n de dividir el equipo en dos grupos:
**Grupo de programaci√≥n:** Juan Jos√© y √Ångela se ofrecieron para desarrollar la parte del c√≥digo, ya que se consider√≥ ineficiente que cinco personas trabajaran en ello simult√°neamente.
**Grupo de an√°lisis y redacci√≥n:** Mariana, Juan Diego y Juan David asumieron la tarea de analizar las preguntas y elaborar las respuestas, adem√°s de redactar el README y la relator√≠a. Mariana se encarg√≥ espec√≠ficamente de la redacci√≥n del README y la relator√≠a, mientras esperaba los avances de Juan Jos√© y √Ångela en la parte t√©cnica.

Se acord√≥ por unanimidad incluir el bono en el parcial. Juan David propuso una base de datos que hab√≠a encontrado y que consideraba √∫til para el proyecto. Sin embargo, al intentar utilizarla, se identific√≥ que los a√±os no coincid√≠an con los de la base de datos del parcial, lo que llev√≥ a Juan David y Juan Diego a buscar nuevas alternativas. A pesar de que en varias bases se encontraron problemas similares con los a√±os, Sergio sugiri√≥ que, por el momento, el equipo se enfocara en las preguntas principales del parcial y dejara el bono para despu√©s.

Finalmente, Juan David encontr√≥ varias bases de datos que comparti√≥ en el grupo para futuras referencias. Para el final de la clase, Juan Jos√© y √Ångela ya hab√≠an avanzado en el procesamiento de los datos, aunque a√∫n quedaban pendientes algunos detalles. En paralelo, Mariana hab√≠a terminado la descripci√≥n del README y la parte inicial de la relator√≠a, mientras que Juan Diego y Juan David revisaron las instrucciones del parcial y analizaron las preguntas sin responderlas a√∫n. 

Se acord√≥ organizar m√°s tarde ese d√≠a para definir c√≥mo finalizar el parcial, ya que en la sesi√≥n del viernes no habr√≠a suficiente tiempo para completarlo. Por la tarde acordamos que el jueves se terminar√≠a la parte del c√≥digo y el an√°lisis, para que el viernes se pudiera resolver cualquier duda restante. Se acord√≥ que el grupo de an√°lisis y redacci√≥n se reuniera el jueves en la noche a las 19h para hacer el an√°lisis, luego de que el grupo de programaci√≥n terminara el c√≥digo.

- **Jueves 13/03/2025**

Al d√≠a siguiente varios integrantes salieron de parciales, por lo que hubo m√°s tiempo para continuar con el parcial. A lo largo del d√≠a, el equipo continu√≥ avanzando en el desarrollo del parcial, asegur√°ndose de que cada miembro comprendiera su rol dentro del proyecto y resolviendo dudas conforme surg√≠an. Se mantuvo una comunicaci√≥n constante a trav√©s del grupo de WhatsApp para coordinar los avances y resolver cualquier inconveniente de manera √°gil. √Ångela se reuni√≥ con Sergio a las 14h para arreglar una parte del procesamiento del script que hab√≠a creado Juan Jos√©, ya que era esencial incluir el nombre de los pa√≠ses, sacarle el promedio a cada a√±o del PIB para otorgarle un n√∫mero y tambi√©n asignarle un valor categ√≥rico a las regiones de 1 a 6. En la tarde noche √Ångela le comparti√≥ al equipo una versi√≥n preliminar del script con el procesamiento de datos ya revisado por Sergio mientras Juan Jos√© continuaba trabajando en los modelos. A las 19h30 Juan Diego, Juan David y Mariana se reunieron para continuar con el an√°lisis de las preguntas. Sin embargo, al revisar el script que estaban desarrollando Juan Jos√© y √Ångela, se encontraron con dificultades para comprender la nomenclatura de la variable del PIB, la cual era clave para clasificar los datos y responder algunas preguntas del parcial. Para resolver esta situaci√≥n, el grupo decidi√≥ contactar a √Ångela, quien explic√≥ la l√≥gica detr√°s del procesamiento de datos que hab√≠an implementado. Gracias a su explicaci√≥n, el equipo pudo continuar con el an√°lisis de manera m√°s eficiente y responder las preguntas de manera fundamentada. Solo hizo falta una de las preguntas, que ten√≠a que ver con la correlaci√≥n entre los datos, puesto que el bloque de c√≥digo.

from ydata_profiling import ProfileReport
reporte_train = ProfileReport(X_train, title="Profiling Report Train dataset")
reporte_train.to_file("reporte_train.html")
reporte_train

no corri√≥ en ninguno de los computadores del equipo de an√°lisis, pero Juan Jos√© s√≠ era capaz de visualizarlo. El equipo le coment√≥ la situaci√≥n a Juan Jos√©, quien les propuso mostrarles los resultados de ese bloque de c√≥digo para que pudieran hacer el an√°lisis de la correlaci√≥n. Luego el viernes el equipo de an√°lisis se dio cuenta de que s√≠ le corr√≠a, solo que no hab√≠an visto d√≥nde se descargaba el reporte del profiling, que era el documento esencial para hacer el an√°lisis. El equipo de an√°lisis respondi√≥ las preguntas del parcial combinando su conocimiento previo, la informaci√≥n obtenida del c√≥digo desarrollado y herramientas de inteligencia artificial como DeepSeek y ChatGPT para validar y complementar sus respuestas. Por ejemplo, al abordar la pregunta sobre los desaf√≠os de una serie de tiempo, inicialmente analizaron la problem√°tica bas√°ndose en lo aprendido en clase. Sin embargo, al contrastar su respuesta con la IA, descubrieron que omit√≠an factores clave como la estacionalidad, la autocorrelaci√≥n y el sesgo en los datos. Esta verificaci√≥n les permiti√≥ ajustar y enriquecer su an√°lisis, asegurando una respuesta m√°s precisa y fundamentada. √Ångela y Juan Jos√© se reunireron con Sergio a las 22h y otros grupos para terminar la parte de los modelos y poderlo enviar al resto para a√±adir al documento de Google Colab las preguntas que se hab√≠an respondido en la reuni√≥n. Juan Jos√© enfrent√≥ varios desaf√≠os al entrenar los modelos de redes neuronales, especialmente para las redes neuronales profundas, al definir los par√°metros clave como la estructura de las capas, el n√∫mero de neuronas por capa, la tasa de dropout, los learning rates, el n√∫mero de √©pocas y el batch size. En primer lugar, la variable y era categ√≥rica, pero el modelo no la aceptaba en ese formato, por lo que tuvo que convertirla a valores num√©ricos, un proceso que result√≥ complejo. Luego, al establecer la capa de salida con tres neuronas, fue necesario aplicar OneHotEncoder para representar correctamente las clases. Adem√°s, inicialmente utiliz√≥ una funci√≥n de p√©rdida incorrecta, cuando en realidad deb√≠a emplear una funci√≥n de p√©rdida categ√≥rica, pero al final se dio cuenta y pudo solucionar la situaci√≥n. Finalmente, tuvo que ajustar la funci√≥n de activaci√≥n para que fuera compatible con la funci√≥n de p√©rdida, asegurando as√≠ un entrenamiento adecuado del modelo.

- **Viernes 14/03/2025**

Temprano en la ma√±ana Juan Jos√© envi√≥ la versi√≥n final del documento de Colab, donde ya estaba el c√≥digo terminado mientras que Mariana continuaba con la relator√≠a. A√±adi√≥ al documento las preguntas respondidas el d√≠a anterior y arregl√≥ un poco la interfaz del documento. En la clase, a las 11h el equipo de an√°lisis se dio cuenta de que hab√≠a otras preguntas que todav√≠a hab√≠a que contestar, por lo que Juan David procedi√≥ a revisarlas mientras que Mariana y Juan Diego terminaban de responder las que quedaban del d√≠a anterior. En ese momento fue cuando se dieron cuenta de que no sab√≠an c√≥mo descargar el reporte de estad√≠sticas descriptivas y Juan Jos√© les ayud√≥. Ya con esto resuleto fue posible terminar de responder las preguntas restantes. Mientras tanto, Juan Jos√©, con ayuda de Juan David, completaron un bono para aumentar la nota. As√≠ es como terminaron de hacer el bono, subieron el documento de nuevo al GitHub para que el equipo de an√°lisis pudiera a√±adir las preguntas al documento, subir a Bloque Ne√≥n el parcial y darlo por finalizado.
